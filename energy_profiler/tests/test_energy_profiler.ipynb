{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../../txf_design-space/')\n",
    "sys.path.append('../../txf_design-space/flexibert')\n",
    "sys.path.append('../../boshnas/boshnas/')\n",
    "sys.path.append('../utils')\n",
    "sys.path.append('../')\n",
    "\n",
    "import yaml\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import shlex\n",
    "import shutil\n",
    "import argparse\n",
    "import subprocess\n",
    "import collections\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from embeddings.utils import graph_util, print_util as pu\n",
    "\n",
    "sys.path.append('../../txf_design-space/transformers/src/transformers')\n",
    "import embedding_util, energy_util\n",
    "\n",
    "from boshnas import BOSHNAS\n",
    "from acq import gosh_acq as acq\n",
    "\n",
    "from transformers import BertModel\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers.models.bert.configuration_bert import BertConfig\n",
    "from transformers.models.bert.modeling_modular_bert import BertModelModular, BertForMaskedLMModular, BertForSequenceClassificationModular\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from run_energy_profiler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated model in tabular dataset: 233489f38df291297bee3ba92de24c06\n",
      "Evaluated model in tabular dataset: c5093d6937238d9cd014503cae891bc7\n",
      "Evaluated model in tabular dataset: 6749823236fe693ccee504e359937975\n",
      "Evaluated model in tabular dataset: a3f5d9305cc6a5346b6c0501057edd84\n",
      "Evaluated model in tabular dataset: 25e3e9a5d81e2a16f1ecd44a6a8ceefa\n",
      "Evaluated model in tabular dataset: 9f910f6a26e43d5189ce063b86a41446\n",
      "Evaluated model in tabular dataset: 64f935f62eca9a1f8a42fbe62a17ddb3\n",
      "Evaluated model in tabular dataset: 65a5e226d7f55d289e135de50997307e\n",
      "Evaluated model in tabular dataset: 85946dcff3ff8f9c4d5446edf5f1d94e\n",
      "Evaluated model in tabular dataset: 6f22fa64b794599aa9b298a701e85d01\n",
      "Evaluated model in tabular dataset: 5e5bc47d7e79e7a6b9c1106769be0dba\n",
      "Evaluated model in tabular dataset: 4549dacaf6b46bbe0933c931705a8940\n",
      "Evaluated model in tabular dataset: 580d4988ac728197889a329f16ae060b\n",
      "Evaluated model in tabular dataset: 3d5c66def824c314a602b7423a5f4903\n",
      "Evaluated model in tabular dataset: 3e08d7f39e8988e4e3afb55c20a15ccf\n",
      "Evaluated model in tabular dataset: 6e2473e3381a6f07165d88ab0df7f462\n",
      "Evaluated model in tabular dataset: fc9fd198d66858cadbba216a5886ef74\n",
      "Max latency:  0.014s/seq. Max energy:  0.881J/seq. Max peak power:  338.232W\n",
      "[  2   1  34  47   1 174 184   2 253  83   0 147  90   3 162  76   2  87\n",
      " 160   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "Evaluated model in tabular dataset: 233489f38df291297bee3ba92de24c06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(tensor([0.]), (tensor([1.]), 0))],\n",
       " [(tensor([0.9998]), (tensor([0.0003]), 0))],\n",
       " [(tensor([1.]), (tensor([1.]), 0))],\n",
       " tensor([2.0003]),\n",
       " 0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load design space\n",
    "design_space = yaml.safe_load(open('../design_space/design_space.yaml'))\n",
    "\n",
    "# Load dataset\n",
    "dataset = json.load(open('../dataset/dataset.json'))\n",
    "for key in dataset.keys():\n",
    "    dataset[key]['embedding'] = eval(dataset[key]['embedding'])\n",
    "    \n",
    "X, latency, energy, peak_power = convert_to_tabular(dataset)\n",
    "max_latency, max_energy, max_peak_power = np.amax(latency), np.amax(energy), np.amax(peak_power)\n",
    "\n",
    "mean_X = np.mean(X, axis=0)\n",
    "\n",
    "# Increase maximum values\n",
    "max_latency, max_energy, max_peak_power = 1.2 * max_latency, 1.2 * max_energy, 1.2 * max_peak_power\n",
    "print(f'Max latency: {max_latency : 0.3f}s/seq. Max energy: {max_energy : 0.3f}J/seq. Max peak power: {max_peak_power : 0.3f}W')\n",
    "    \n",
    "# Get the embedding for model with hash: 233489f38df291297bee3ba92de24c06\n",
    "model_hash = '233489f38df291297bee3ba92de24c06'\n",
    "print(np.array(dataset[model_hash]['embedding']))\n",
    "\n",
    "# Get initialization parameters\n",
    "embedding_dim = len(dataset[list(dataset.keys())[0]]['embedding'])\n",
    "embedding_bounds = embedding_util.get_embedding_bounds(design_space, 'all')\n",
    "\n",
    "max_X = np.array([bound[1] for bound in embedding_bounds])\n",
    "\n",
    "embedding_bounds = (np.array([bound[0] for bound in embedding_bounds]), np.array([bound[1] for bound in embedding_bounds]))\n",
    "\n",
    "normalized_embedding_bounds = \\\n",
    "    (np.array([0 for i in range(embedding_dim)]), np.array([1 for i in range(embedding_dim)]))    \n",
    "\n",
    "surrogate_models = \\\n",
    "    init_surrogate_models(embedding_dim, embedding_bounds, '../dataset/surrogate_models/', True)\n",
    "\n",
    "X_ds = convert_to_tabular({model_hash: dataset[model_hash]}, only_embeddings=True)\n",
    "\n",
    "# We see a non-zero epistemic uncertainty\n",
    "get_predictions(surrogate_models, X_ds-mean_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(tensor([0.5864]), (tensor([0.5780]), 0)),\n",
       "  (tensor([0.5845]), (tensor([0.5760]), 0)),\n",
       "  (tensor([0.5921]), (tensor([0.5802]), 0)),\n",
       "  (tensor([0.5904]), (tensor([0.5779]), 0)),\n",
       "  (tensor([0.5851]), (tensor([0.5775]), 0)),\n",
       "  (tensor([0.5894]), (tensor([0.5811]), 0)),\n",
       "  (tensor([0.5873]), (tensor([0.5749]), 0)),\n",
       "  (tensor([0.5817]), (tensor([0.5772]), 0)),\n",
       "  (tensor([0.5884]), (tensor([0.5722]), 0)),\n",
       "  (tensor([0.5807]), (tensor([0.5745]), 0)),\n",
       "  (tensor([0.5843]), (tensor([0.5707]), 0)),\n",
       "  (tensor([0.5852]), (tensor([0.5775]), 0)),\n",
       "  (tensor([0.5843]), (tensor([0.5737]), 0)),\n",
       "  (tensor([0.5832]), (tensor([0.5757]), 0)),\n",
       "  (tensor([0.5843]), (tensor([0.5773]), 0)),\n",
       "  (tensor([0.5869]), (tensor([0.5772]), 0)),\n",
       "  (tensor([0.5847]), (tensor([0.5777]), 0))],\n",
       " [(tensor([0.4938]), (tensor([0.4330]), 0)),\n",
       "  (tensor([0.4937]), (tensor([0.4276]), 0)),\n",
       "  (tensor([0.4958]), (tensor([0.4326]), 0)),\n",
       "  (tensor([0.4952]), (tensor([0.4236]), 0)),\n",
       "  (tensor([0.4896]), (tensor([0.4296]), 0)),\n",
       "  (tensor([0.4892]), (tensor([0.4253]), 0)),\n",
       "  (tensor([0.4944]), (tensor([0.4291]), 0)),\n",
       "  (tensor([0.4913]), (tensor([0.4255]), 0)),\n",
       "  (tensor([0.4971]), (tensor([0.4236]), 0)),\n",
       "  (tensor([0.4921]), (tensor([0.4331]), 0)),\n",
       "  (tensor([0.4970]), (tensor([0.4256]), 0)),\n",
       "  (tensor([0.4882]), (tensor([0.4290]), 0)),\n",
       "  (tensor([0.4879]), (tensor([0.4308]), 0)),\n",
       "  (tensor([0.4881]), (tensor([0.4319]), 0)),\n",
       "  (tensor([0.4887]), (tensor([0.4292]), 0)),\n",
       "  (tensor([0.4888]), (tensor([0.4312]), 0)),\n",
       "  (tensor([0.4878]), (tensor([0.4311]), 0))],\n",
       " [(tensor([0.4811]), (tensor([0.5536]), 0)),\n",
       "  (tensor([0.4833]), (tensor([0.5549]), 0)),\n",
       "  (tensor([0.4782]), (tensor([0.5517]), 0)),\n",
       "  (tensor([0.4795]), (tensor([0.5533]), 0)),\n",
       "  (tensor([0.4759]), (tensor([0.5504]), 0)),\n",
       "  (tensor([0.4795]), (tensor([0.5494]), 0)),\n",
       "  (tensor([0.4780]), (tensor([0.5556]), 0)),\n",
       "  (tensor([0.4868]), (tensor([0.5495]), 0)),\n",
       "  (tensor([0.4835]), (tensor([0.5548]), 0)),\n",
       "  (tensor([0.4901]), (tensor([0.5516]), 0)),\n",
       "  (tensor([0.4789]), (tensor([0.5560]), 0)),\n",
       "  (tensor([0.4789]), (tensor([0.5506]), 0)),\n",
       "  (tensor([0.4761]), (tensor([0.5522]), 0)),\n",
       "  (tensor([0.4787]), (tensor([0.5528]), 0)),\n",
       "  (tensor([0.4783]), (tensor([0.5509]), 0)),\n",
       "  (tensor([0.4784]), (tensor([0.5508]), 0)),\n",
       "  (tensor([0.4796]), (tensor([0.5528]), 0))],\n",
       " tensor([1.5646]),\n",
       " 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(surrogate_models, (X-mean_X)/max_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(tensor([0.4834]), (tensor([0.0625]), 0)),\n",
       "  (tensor([0.4482]), (tensor([0.0661]), 0)),\n",
       "  (tensor([0.5132]), (tensor([0.0630]), 0)),\n",
       "  (tensor([0.5275]), (tensor([0.0663]), 0)),\n",
       "  (tensor([0.2622]), (tensor([0.0646]), 0)),\n",
       "  (tensor([0.8217]), (tensor([0.0621]), 0)),\n",
       "  (tensor([0.5896]), (tensor([0.0653]), 0)),\n",
       "  (tensor([0.7882]), (tensor([0.0620]), 0)),\n",
       "  (tensor([0.5783]), (tensor([0.0616]), 0)),\n",
       "  (tensor([0.5036]), (tensor([0.0645]), 0)),\n",
       "  (tensor([0.6091]), (tensor([0.0650]), 0)),\n",
       "  (tensor([0.2616]), (tensor([0.0651]), 0)),\n",
       "  (tensor([0.2589]), (tensor([0.0644]), 0)),\n",
       "  (tensor([0.3191]), (tensor([0.0645]), 0)),\n",
       "  (tensor([0.2489]), (tensor([0.0648]), 0)),\n",
       "  (tensor([0.2565]), (tensor([0.0650]), 0)),\n",
       "  (tensor([0.2837]), (tensor([0.0652]), 0))],\n",
       " [(tensor([0.4703]), (tensor([0.0603]), 0)),\n",
       "  (tensor([0.4575]), (tensor([0.0575]), 0)),\n",
       "  (tensor([0.4970]), (tensor([0.0597]), 0)),\n",
       "  (tensor([0.5043]), (tensor([0.0565]), 0)),\n",
       "  (tensor([0.2690]), (tensor([0.0599]), 0)),\n",
       "  (tensor([0.8077]), (tensor([0.0582]), 0)),\n",
       "  (tensor([0.5433]), (tensor([0.0587]), 0)),\n",
       "  (tensor([0.7854]), (tensor([0.0545]), 0)),\n",
       "  (tensor([0.5550]), (tensor([0.0547]), 0)),\n",
       "  (tensor([0.5070]), (tensor([0.0571]), 0)),\n",
       "  (tensor([0.5771]), (tensor([0.0553]), 0)),\n",
       "  (tensor([0.2554]), (tensor([0.0594]), 0)),\n",
       "  (tensor([0.2676]), (tensor([0.0605]), 0)),\n",
       "  (tensor([0.3144]), (tensor([0.0603]), 0)),\n",
       "  (tensor([0.2472]), (tensor([0.0599]), 0)),\n",
       "  (tensor([0.2683]), (tensor([0.0603]), 0)),\n",
       "  (tensor([0.2701]), (tensor([0.0608]), 0))],\n",
       " [(tensor([0.6521]), (tensor([0.0631]), 0)),\n",
       "  (tensor([0.5920]), (tensor([0.0634]), 0)),\n",
       "  (tensor([0.5543]), (tensor([0.0612]), 0)),\n",
       "  (tensor([0.4941]), (tensor([0.0598]), 0)),\n",
       "  (tensor([0.4048]), (tensor([0.0619]), 0)),\n",
       "  (tensor([0.6112]), (tensor([0.0578]), 0)),\n",
       "  (tensor([0.7143]), (tensor([0.0633]), 0)),\n",
       "  (tensor([0.8454]), (tensor([0.0575]), 0)),\n",
       "  (tensor([0.4647]), (tensor([0.0612]), 0)),\n",
       "  (tensor([0.5847]), (tensor([0.0597]), 0)),\n",
       "  (tensor([0.6296]), (tensor([0.0646]), 0)),\n",
       "  (tensor([0.4524]), (tensor([0.0623]), 0)),\n",
       "  (tensor([0.4226]), (tensor([0.0619]), 0)),\n",
       "  (tensor([0.5191]), (tensor([0.0629]), 0)),\n",
       "  (tensor([0.4739]), (tensor([0.0621]), 0)),\n",
       "  (tensor([0.3789]), (tensor([0.0625]), 0)),\n",
       "  (tensor([0.4399]), (tensor([0.0631]), 0))],\n",
       " tensor([0.1891]),\n",
       " 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train surrogate models on the normalized dataset\n",
    "latency, energy, peak_power = latency/max_latency, energy/max_energy, peak_power/max_peak_power\n",
    "train_surrogate_models(surrogate_models, (X-mean_X)/max_X, latency, energy, peak_power)\n",
    "\n",
    "# We see a non-zero epistemic uncertainty\n",
    "get_predictions(surrogate_models, (X-mean_X)/max_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.50794941, 0.46322158, 0.5299725 , 0.55653288, 0.28797305,\n",
       "        0.83333333, 0.6225946 , 0.82762999, 0.5978553 , 0.50909825,\n",
       "        0.63592478, 0.28402982, 0.28320672, 0.34924548, 0.2638582 ,\n",
       "        0.27996118, 0.3165051 ]),\n",
       " array([0.46015746, 0.47726582, 0.51435174, 0.52287294, 0.2386085 ,\n",
       "        0.83333333, 0.59214409, 0.81465537, 0.58527834, 0.50316834,\n",
       "        0.62450576, 0.20652767, 0.24696664, 0.3017484 , 0.23711017,\n",
       "        0.28845448, 0.22602613]),\n",
       " array([0.63790534, 0.67373874, 0.58835356, 0.4624932 , 0.3267284 ,\n",
       "        0.61936777, 0.74753424, 0.83333333, 0.4472374 , 0.55160363,\n",
       "        0.63335226, 0.39762648, 0.43721469, 0.56476028, 0.60987724,\n",
       "        0.37214102, 0.3810698 ]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latency, energy, peak_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06571674346923828"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get random samples of the entire dataset to obtain maximum uncertainty\n",
    "random_samples = embedding_util.get_samples(design_space, num_samples=16, sampling_method='Random', debug=False)\n",
    "X_ds = convert_to_tabular(random_samples, only_embeddings=True)\n",
    "\n",
    "get_predictions(surrogate_models, (X_ds-mean_X)/max_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.50794941, 0.46322158, 0.5299725 , 0.55653288, 0.28797305,\n",
      "       0.83333333, 0.6225946 , 0.82762999, 0.5978553 , 0.50909825,\n",
      "       0.63592478, 0.28402982, 0.28320672, 0.34924548, 0.2638582 ,\n",
      "       0.27996118, 0.3165051 ]), array([1.00000004e-05, 1.00000004e-05, 1.00000004e-05, 1.00000004e-05,\n",
      "       1.00000004e-05, 1.00000004e-05, 1.00000004e-05, 1.00000004e-05,\n",
      "       1.00000004e-05, 1.00000004e-05, 1.00000004e-05, 1.00000004e-05,\n",
      "       1.00000004e-05, 1.00000004e-05, 1.00000004e-05, 1.00000004e-05,\n",
      "       1.00000004e-05]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.        , 0.        , 0.6225946 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.83333333,\n",
       "        0.28797305, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]),\n",
       " array([1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000004e-05,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000004e-05, 1.00000004e-05, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test GP\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "gpr = GaussianProcessRegressor(random_state=0)\n",
    "gpr.fit(X, latency)\n",
    "\n",
    "print(gpr.predict(X, return_std=True))\n",
    "gpr.predict(X_ds, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<class 'boshnas.BOSHNAS'>\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(type(surrogate_models[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txf_design-space [~/.conda/envs/txf_design-space/]",
   "language": "python",
   "name": "conda_txf_design-space"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
